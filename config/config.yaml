# QA System Configuration

# Security & API Configuration
# Note: These values are loaded from environment variables
SECURITY:
  API_KEY: ${API_KEY}  # Loaded from .env
  GOOGLE_CLOUD_PROJECT: ${GOOGLE_CLOUD_PROJECT}  # Loaded from .env
  GOOGLE_APPLICATION_CREDENTIALS: ${GOOGLE_APPLICATION_CREDENTIALS}  # Loaded from .env
  AUTH_REQUIRED: true

# Vector Database Configuration
VECTOR_STORE:
  TYPE: "chroma"  # Using ChromaDB as the vector store implementation
  PERSIST_DIRECTORY: "./data/vector_store"
  COLLECTION_NAME: "qa_documents"
  # Distance metric used to calculate similarity between queries and documents
  # Options:
  #   "cosine" - Measures cosine similarity between vectors (most common)
  #   "euclidean" - Measures straight-line distance between vectors
  #   "dot" - Measures dot product between vectors
  # Cosine similarity is preferred as it's less sensitive to document length
  # Default: "cosine"
  DISTANCE_METRIC: "cosine"

  # Number of most similar documents to retrieve initially
  # This is the first-pass retrieval before applying relevance scoring
  # Higher values cast a wider net but increase processing time
  # Lower values are faster but might miss relevant documents
  # Range: 1-100, Default: 10
  TOP_K: 40

  # Maximum number of tokens (words/characters) allowed in the generated response
  # Higher values allow for longer, more detailed responses but may take longer to generate
  # Range: 1-4096, Default: 2048
  MAX_TOKENS: 2048

  EMBEDDING_DIM: 3072  # This is the maximum dimension for Gemini's embedding model

QUERY_ENGINE:
  # Controls the randomness/creativity of the response
  # Lower values (0.0-0.3) are more focused and deterministic
  # Higher values (0.7-1.0) are more creative but potentially less precise
  # Range: 0.0-1.0, Default: 0.3
  TEMPERATURE: 0.3

  # Controls the cumulative probability cutoff for token selection
  # Affects the diversity of generated responses
  # Lower values are more focused, higher values allow more variety
  # Range: 0.0-1.0, Default: 0.95
  TOP_P: 0.95

  # Determines how the system formats its responses
  # Options:
  #   "comprehensive" - Detailed responses with context and explanations
  #   "concise" - Brief, direct answers
  #   "bullet_points" - Organized as bullet points
  RESPONSE_MODE: "comprehensive"

  # Minimum similarity score required for a document to be considered relevant
  # Higher values (e.g., 0.8) mean only very close matches are included
  # Lower values (e.g., 0.4) allow more contextual information but may include less relevant matches
  # Range: 0.0-1.0, Default: 0.4
  MIN_RELEVANCE_SCORE: 0.4

  # Maximum number of relevant documents to include in the context when answering
  # Higher values provide more context but may slow down response generation
  # Lower values are faster but might miss relevant information
  # Range: 1-50, Default: 20
  MAX_CONTEXT_DOCS: 20

  # Whether to expand the user's query to improve search results
  # When true: System will try to add relevant terms to improve search accuracy
  # When false: System will use the exact query as provided
  # Default: false
  ENABLE_QUERY_EXPANSION: true  # Enable query expansion for better search results

# Document Processing
DOCUMENT_PROCESSING:
  # Default path for documents to be processed and indexed
  DOCUMENT_PATH: "./docs"

  # Maximum size of each text chunk when splitting documents
  # Documents are split into smaller chunks for better processing and retrieval
  # Larger chunks retain more context but may be less precise
  # Smaller chunks are more precise but may lose context
  # Range: 100-2000, Default: 1000 characters
  MAX_CHUNK_SIZE: 800

  # Number of characters to overlap between consecutive chunks
  # Helps maintain context across chunk boundaries
  # Example: With size 1000 and overlap 200:
  #   Chunk 1: [0-1000], Chunk 2: [800-1800], etc.
  # Higher values ensure better context but increase storage needs
  # Recommended: 10-20% of MAX_CHUNK_SIZE
  # Range: 0-500, Default: 200 characters
  CHUNK_OVERLAP: 200

  # Number of parallel processing tasks for document indexing
  # Higher values speed up processing but use more system resources
  # Should be set based on available CPU cores
  # For 4-core CPU: 4 is optimal
  # For 8-core CPU: 6-8 is optimal
  # Range: 1-16, Default: 4
  CONCURRENT_TASKS: 6

  # Number of documents to process in each batch
  # Affects memory usage and processing efficiency
  # Larger batches are more efficient but use more memory
  # Smaller batches use less memory but take longer
  # Range: 1-100, Default: 10
  BATCH_SIZE: 10
  EXCLUDE_PATTERNS:
    - "**/.*/**"  # Hidden files and directories
    - "**/_*/**"  # Files/dirs starting with underscore
 

# Logging Configuration
LOGGING:
  LEVEL: "INFO"
  FORMAT: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  DATE_FORMAT: "%Y-%m-%d %H:%M:%S"
  LOG_FILE: "logs/qa_system.log"
  ENABLE_DEBUG: false

# Embedding Model Configuration
EMBEDDING_MODEL:
  # Type of embedding model to use
  # Options:
  #   "openai" - OpenAI's text-embedding-ada-002 model
  #   "huggingface" - HuggingFace models
  #   "local" - Local models
  #   "gemini" - Google's Gemini embedding model
  TYPE: "gemini"
  
  # Model name for Gemini embeddings
  MODEL_NAME: "models/gemini-embedding-exp-03-07"
  
  # Batch size for processing multiple texts at once
  # Higher values are more efficient but use more memory
  # Limited by rate limit of 1,500 requests per minute
  # Range: 1-100, Default: 8
  BATCH_SIZE: 10
  
  # Maximum length of text to embed (in tokens)
  # Texts longer than this will be truncated
  # For Gemini embeddings: max 8,192 tokens
  MAX_LENGTH: 8192
  
  # Output embedding dimensions
  # Gemini embeddings support flexible dimensions:
  # Options: 3072, 1536, or 768
  # Choose based on your needs:
  # - 3072: Highest quality but more storage/compute intensive
  # - 1536: Good balance of quality and resource usage
  # - 768: Most efficient, suitable for many applications
  DIMENSIONS: 3072  # Set to 3072 to match vector store configuration
  
  # Gemini API Rate Limiting Configuration
  RATE_LIMITS:
    MAX_REQUESTS_PER_MINUTE: 30    # Gemini API quota limit
    MAX_CONCURRENT_REQUESTS: 5      # Maximum parallel requests
    BACKOFF_FACTOR: 2              # Exponential backoff for retries
    MAX_RETRIES: 5                 # Maximum retry attempts
    INITIAL_RETRY_DELAY: 2         # Initial retry delay in seconds
    MAX_RETRY_DELAY: 120           # Maximum retry delay in seconds

# Application Settings
APP:
  BASE_DIR: "."
  TIMEOUT: 30
  MAX_RETRIES: 3
  API_PORT: 8000 